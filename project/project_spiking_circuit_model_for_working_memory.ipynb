{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "project-spiking circuit model for working memory.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYEvhWRHVskMO1GwXjiSu9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/cahcharm/Neuro-and-Complexity-Science/blob/CSHA2021/project/project_spiking_circuit_model_for_working_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spiking circuit model for working memory**\r\n",
        "\r\n",
        "Building up a spiking circuit model for working memory (Misha, Science, 2008). \r\n",
        "\r\n",
        "* Step 1: build LIF neuron, voltage jump synapse, STP synapse\r\n",
        "*\tStep 2: consider the connectivity used in the paper, build up the network model\r\n",
        "*\tStep 3: try to encode one item in the model (Fig. 2)\r\n",
        "*\tStep 4: try to encode two items in the network (Fig. 3)\r\n"
      ],
      "metadata": {
        "id": "U4qCoFCTEVnd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pip install brainpy-simulator"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting brainpy-simulator\n",
            "  Downloading brainpy-simulator-1.0.2.tar.gz (126 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 126 kB 22.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from brainpy-simulator) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.2 in /usr/local/lib/python3.7/dist-packages (from brainpy-simulator) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2->brainpy-simulator) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2->brainpy-simulator) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2->brainpy-simulator) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2->brainpy-simulator) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.2->brainpy-simulator) (1.15.0)\n",
            "Building wheels for collected packages: brainpy-simulator\n",
            "  Building wheel for brainpy-simulator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for brainpy-simulator: filename=brainpy_simulator-1.0.2-py3-none-any.whl size=152104 sha256=9f06600e7cae45df374868e5bf2a479323deb0d8f09fa10e384b56b8b5f22c64\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/1c/3f/e33093b69bc03ff9b2742480ec6126ddef875ba4f6d3699659\n",
            "Successfully built brainpy-simulator\n",
            "Installing collected packages: brainpy-simulator\n",
            "Successfully installed brainpy-simulator-1.0.2\n"
          ]
        }
      ],
      "metadata": {
        "id": "LsX1Lx6HEVLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9551f0-65cb-4250-d741-ded7df2afff4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import brainpy as bp\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.colors as mcolors"
      ],
      "outputs": [],
      "metadata": {
        "id": "n_192zL9EQ4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: build LIF neuron, voltage jump synapse, STP synapse"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIF Neuron**"
      ],
      "metadata": {
        "id": "LkLRyRoD6mMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class LIF(bp.NeuGroup):\r\n",
        "  target_backend = ['numpy', 'numba']\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  @bp.odeint(method='exponential_euler')\r\n",
        "  def integral(V, t, Iext, V_rest, R, tau):\r\n",
        "    dvdt = (-V + V_rest + R * Iext) / tau\r\n",
        "    return dvdt\r\n",
        "\r\n",
        "  def __init__(self, size, t_ref=1., V_rest=0., V_reset=0., \r\n",
        "               V_th=20., R=1., tau=10., **kwargs):\r\n",
        "    super(LIF, self).__init__(size=size, **kwargs)\r\n",
        "    \r\n",
        "    # parameters\r\n",
        "    self.V_rest = V_rest\r\n",
        "    self.V_reset = V_reset\r\n",
        "    self.V_th = V_th\r\n",
        "    self.R = R\r\n",
        "    self.tau = tau\r\n",
        "    self.t_ref = t_ref\r\n",
        "\r\n",
        "    # variables\r\n",
        "    self.t_last_spike = bp.ops.ones(self.num) * -1e7\r\n",
        "    self.refractory = bp.ops.zeros(self.num, dtype=bool)\r\n",
        "    self.spike = bp.ops.zeros(self.num, dtype=bool)\r\n",
        "    self.V = bp.ops.ones(self.num) * V_rest\r\n",
        "    self.input = bp.ops.zeros(self.num)\r\n",
        "\r\n",
        "  def update(self, _t):\r\n",
        "    for i in range(self.num):\r\n",
        "      spike = False\r\n",
        "      refractory = (_t - self.t_last_spike[i]) <= self.t_ref\r\n",
        "      if not refractory:\r\n",
        "        V = self.integral(self.V[i], _t, self.input[i],\r\n",
        "                          self.V_rest, self.R, self.tau)\r\n",
        "        spike = (V >= self.V_th)\r\n",
        "        if spike:\r\n",
        "          V = self.V_reset\r\n",
        "          self.t_last_spike[i] = _t\r\n",
        "          refractory = True\r\n",
        "        self.V[i] = V\r\n",
        "      self.spike[i] = spike\r\n",
        "      self.refractory[i] = refractory\r\n",
        "      self.input[i] = 0."
      ],
      "outputs": [],
      "metadata": {
        "id": "FyRN3T4t6h0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Voltage Jump Synapse**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\r\n",
        "I = \\sum_{j\\in C} g \\delta(t-t_j-D)\r\n",
        "$$\r\n",
        "\r\n",
        "where $g$ denotes the chemical synaptic strength, $t_j$ the spiking moment of the presynaptic neuron $j$, $C$ the set of neurons in the encoding layer, and $D$ the transmission delay of chemical synapses. For simplicity, we omit the rise and decay phases of post-synaptic currents. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class VoltageJump(bp.TwoEndConn):\r\n",
        "    target_backend = ['numpy', 'numba']\r\n",
        "\r\n",
        "    def __init__(self, pre, post, conn, delay=0., post_refractory=False, weight=1., **kwargs):\r\n",
        "        # parameters\r\n",
        "        self.delay = delay\r\n",
        "        self.post_has_refractory = post_refractory\r\n",
        "\r\n",
        "        # connections\r\n",
        "        self.conn = conn(pre.size, post.size)\r\n",
        "        self.pre_ids, self.post_ids = conn.requires('pre_ids', 'post_ids')\r\n",
        "        self.num = len(self.pre_ids)\r\n",
        "\r\n",
        "        # variables\r\n",
        "        self.s = np.zeros(self.num)\r\n",
        "        self.w = np.ones(self.num) * weight\r\n",
        "        self.I_syn = self.register_constant_delay('I_syn', size=self.num, delay_time=delay)\r\n",
        "\r\n",
        "        super(VoltageJump, self).__init__(pre=pre, post=post, **kwargs)\r\n",
        "        \r\n",
        "        # checking\r\n",
        "        assert hasattr(pre, 'V'), 'Pre-synaptic group must has \"V\" variable.'\r\n",
        "        assert hasattr(post, 'V'), 'Post-synaptic group must has \"V\" variable.'\r\n",
        "        assert hasattr(post, 'input'), 'Post-synaptic group must has \"input\" variable.'\r\n",
        "        if post_refractory:\r\n",
        "            assert hasattr(post, 'refractory'), 'Post-synaptic group must has \"refractory\" variable.'\r\n",
        "\r\n",
        "    def update(self, _t):\r\n",
        "        for i in range(self.num):\r\n",
        "            pre_id = self.pre_ids[i]\r\n",
        "            post_id = self.post_ids[i]\r\n",
        "            # update\r\n",
        "            self.s[i] = self.pre.spike[pre_id]\r\n",
        "            self.I_syn.push(i, self.s[i] * self.w[i])\r\n",
        "            # output\r\n",
        "            I_syn = self.I_syn.pull(i)\r\n",
        "            if self.post_has_refractory:\r\n",
        "                self.post.V += I_syn * (1. - self.post.refractory[post_id])\r\n",
        "            else:\r\n",
        "                self.post.V += I_syn"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "neu1 = LIF(1, monitors=['V', 'spike'])\r\n",
        "neu2 = LIF(1, monitors=['V'])\r\n",
        "\r\n",
        "syn1 = VoltageJump(pre=neu1, post=neu2, conn=bp.connect.All2All(), delay=2.0)\r\n",
        "\r\n",
        "net = bp.Network(neu1, syn1, neu2)\r\n",
        "net.run(150., inputs=[(neu1, 'input', 25.), (neu2, 'input', 10.)])\r\n",
        "\r\n",
        "fig, gs = bp.visualize.get_figure(1, 1, 3, 8)\r\n",
        "plt.plot(net.ts, neu1.mon.V, label='pre-V')\r\n",
        "plt.plot(net.ts, neu2.mon.V, label='post-V')\r\n",
        "plt.xlim(40, 150)\r\n",
        "plt.legend()\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "unztZ0rQ7Jls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STP Synapse**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\frac{d u}{d t}= -\\frac{u}{\\tau_{f}}+U\\left(1-u^{-}\\right) \\delta\\left(t-t_{s p}\\right)$$\r\n",
        "\r\n",
        "$$\\frac{d x}{d t}= \\frac{1-x}{\\tau_{d}}-u^{+} x^{-} \\delta\\left(t-t_{s p}\\right)$$\r\n",
        "\r\n",
        "$$\\frac{d I}{d t}= -\\frac{I}{\\tau_{s}}+A u^{+} x^{-} \\delta\\left(t-t_{s p}\\right)$$\r\n",
        "\r\n",
        "$$u^{+}=u^{-}+U\\left(1-u^{-}\\right)$$\r\n",
        "\r\n",
        "Or we can see the dynamics as:\r\n",
        "\r\n",
        "$$\r\n",
        "\\frac {du} {dt} = - \\frac u {\\tau_f} \r\n",
        "$$\r\n",
        "\r\n",
        "$$\r\n",
        "\\frac {dx} {dt} =  \\frac {1-x} {\\tau_d} \r\n",
        "$$\r\n",
        "\r\n",
        "$$\r\n",
        "\\frac {dI} {dt} = - \\frac I {\\tau}\r\n",
        "$$\r\n",
        "\r\n",
        "$$\r\n",
        "\\rm{if (pre \\ fire), then}\r\n",
        "\\begin{cases} \r\n",
        "u^+ = u^- + U(1-u^-) \\\\ \r\n",
        "I^+ = I^- + Au^+x^- \\\\\r\n",
        "x^+ = x^- - u^+x^- \r\n",
        "\\end{cases}\r\n",
        "$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class STP(bp.TwoEndConn):\r\n",
        "  target_backend = 'general'\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  @bp.odeint(method='exponential_euler')\r\n",
        "  def integral(s, u, x, t, tau, tau_d, tau_f):\r\n",
        "    # Dynamics\r\n",
        "    dsdt = - s / tau \r\n",
        "    dudt = - u / tau_f \r\n",
        "    dxdt = (1 - x) / tau_d\r\n",
        "    return dsdt, dudt, dxdt\r\n",
        "  \r\n",
        "  def __init__(self, pre, post, conn, delay=0., U=0.15, tau_f=1500., tau_d=200., tau=8., A=1.,  **kwargs):\r\n",
        "    # parameters\r\n",
        "    self.tau_d = tau_d\r\n",
        "    self.tau_f = tau_f\r\n",
        "    self.tau = tau\r\n",
        "    self.U = U\r\n",
        "    self.delay = delay\r\n",
        "\r\n",
        "    # connections\r\n",
        "    self.conn = conn(pre.size, post.size)\r\n",
        "    self.pre_ids, self.post_ids = conn.requires('pre_ids', 'post_ids')\r\n",
        "    self.num = len(self.pre_ids)\r\n",
        "\r\n",
        "    # variables\r\n",
        "    self.s = bp.ops.zeros(self.num)\r\n",
        "    self.x = bp.ops.ones(self.num)\r\n",
        "    self.u = bp.ops.zeros(self.num)\r\n",
        "    self.A = A\r\n",
        "    self.I_syn = self.register_constant_delay('I_syn', size=self.num, delay_time=delay)\r\n",
        "    \r\n",
        "    super(STP, self).__init__(pre=pre, post=post, **kwargs)\r\n",
        "\r\n",
        "  def update(self, _t):\r\n",
        "    for i in range(self.num):\r\n",
        "      pre_id, post_id = self.pre_ids[i], self.post_ids[i]\r\n",
        "\r\n",
        "      self.s[i], u, x = self.integral(self.s[i], self.u[i], self.x[i], _t, self.tau, self.tau_d, self.tau_f)\r\n",
        "      if self.pre.spike[pre_id]:\r\n",
        "        # update if there is a spike\r\n",
        "        u += self.U * (1 - self.u[i])\r\n",
        "        self.s[i] += self.A * u * self.x[i]  \r\n",
        "        x -= u * self.x[i]\r\n",
        "      self.u[i] = u\r\n",
        "      self.x[i] = x\r\n",
        "\r\n",
        "      # output\r\n",
        "      self.I_syn.push(i, self.s[i])\r\n",
        "      self.post.input[post_id] += self.I_syn.pull(i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## STD/STF parameters and plot \r\n",
        "neu1 = LIF(1, monitors=['V'])\r\n",
        "neu2 = LIF(1, monitors=['V'])\r\n",
        "\r\n",
        "# STD\r\n",
        "syn = STP(U=0.2, tau_d=150., tau_f=2., pre=neu1, post=neu2, \r\n",
        "          conn=bp.connect.All2All(), monitors=['s', 'u', 'x'])\r\n",
        "net = bp.Network(neu1, syn, neu2)\r\n",
        "net.run(100., inputs=(neu1, 'input', 28.))\r\n",
        "\r\n",
        "# plot\r\n",
        "fig, gs = bp.visualize.get_figure(2, 1, 3, 7)\r\n",
        "\r\n",
        "fig.add_subplot(gs[0, 0])\r\n",
        "plt.plot(net.ts, syn.mon.u[:, 0], label='u')\r\n",
        "plt.plot(net.ts, syn.mon.x[:, 0], label='x')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "fig.add_subplot(gs[1, 0])\r\n",
        "plt.plot(net.ts, syn.mon.s[:, 0], label='s')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.xlabel('Time (ms)')\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ll7DKEVw7akn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: consider the connectivity used in the paper, build up the network model"
      ],
      "metadata": {
        "id": "_cPuoNW664kw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dt = 0.0001  # [s]\r\n",
        "bp.backend.set(dt=dt)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# the parameters of network\r\n",
        "alpha = 1.5\r\n",
        "J_EE = 8.  # the connection strength in each excitatory neural clusters\r\n",
        "J_IE = 1.75  # Synaptic efficacy E → I\r\n",
        "J_EI = 1.1  # Synaptic efficacy I → E\r\n",
        "tau_f = 1.5  # time constant of STF  [s]\r\n",
        "tau_d = .3  # time constant of STD  [s]\r\n",
        "U = 0.3  # minimum STF value\r\n",
        "tau = 0.008  # time constant of firing rate of the excitatory neurons [s]\r\n",
        "tau_I = tau  # time constant of firing rate of the inhibitory neurons\r\n",
        "\r\n",
        "Ib = 8.  # background input and external input\r\n",
        "Iinh = 0.  # the background input of inhibtory neuron\r\n",
        "\r\n",
        "cluster_num = 16  # the number of the clusters"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# the parameters of external input\r\n",
        "\r\n",
        "stimulus_num = 5\r\n",
        "Iext_train = 225  # the strength of the external input\r\n",
        "# the time interval between the consequent external input [s]\r\n",
        "Ts_interval = 0.070\r\n",
        "Ts_duration = 0.030  # the time duration of the external input [s]\r\n",
        "duration = 2.500  # [s]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "the working memory model based on STP was used to derive the expression for the postsynaptic current resulting from the activity of a large, uncorrelated pre-synaptic population.\r\n",
        "\r\n",
        "The resulting network model has three differential equations for each of $P$ excitatory clusters (synaptic current $h_\\mu$ and two STP variables $u_\\mu$ and $x_\\mu$ for each cluster $\\mu; \\mu = 1,..., P$) and one additional equation for the inhibitory pool current $h_I$:\r\n",
        "\r\n",
        "$$\r\n",
        "\\begin{gathered}\r\n",
        "\\tau \\frac{d h_{\\mu}}{d t}=-h_{\\mu}+J_{E E} u_{\\mu} x_{\\mu} R_{\\mu}-J_{E l} R_{l}+I_{b}+I_{e}(t) \\\\\r\n",
        "\\frac{d u_{\\mu}}{d t}=\\frac{U-u_{\\mu}}{\\tau_{f}}+U\\left(1-u_{\\mu}\\right) R_{\\mu} \\\\\r\n",
        "\\frac{d x_{\\mu}}{d t}=\\frac{1-x_{\\mu}}{\\tau_{d}}-u_{\\mu} x_{\\mu} R_{\\mu}, \\text { and } \\\\\r\n",
        "\\tau \\frac{d h_{I}}{d t}=-h_{I}+J_{I E} \\sum_{\\nu} R_{\\nu}\r\n",
        "\\end{gathered}\r\n",
        "$$\r\n",
        "\r\n",
        "where $t$ is the neuronal time constant, for simplicity the same for excitation and inhibition; $I_b$ is the constant background excitation; and $I_e$ is the external input used to load memory items into the network. \r\n",
        "\r\n",
        "$$\r\n",
        "R(h)=\\alpha \\ln (1+\\exp (h / \\alpha))\r\n",
        "$$\r\n",
        "\r\n",
        "is neuronal gain chosen in the form of a smoothed threshold-linear function, also the same for excitatory and inhibitory neurons. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# the excitatory cluster model and the inhibitory pool model\r\n",
        "\r\n",
        "class WorkingMemoryModel(bp.NeuGroup):\r\n",
        "  target_backend = ['numpy', 'numba']\r\n",
        "\r\n",
        "  def __init__(self, size, **kwargs):\r\n",
        "    self.inh_h = 0.\r\n",
        "    self.inh_r = self.log(self.inh_h)\r\n",
        "    self.u = bp.ops.ones(cluster_num) * U\r\n",
        "    self.x = bp.ops.ones(cluster_num)\r\n",
        "    self.h = bp.ops.zeros(cluster_num)\r\n",
        "    self.r = self.log(self.h)\r\n",
        "    self.input = bp.ops.zeros(cluster_num)\r\n",
        "\r\n",
        "    super(WorkingMemoryModel, self).__init__(size, **kwargs)\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  @bp.odeint\r\n",
        "  def int_exc(u, x, h, t, r, r_inh, Iext):\r\n",
        "    du = (U - u) / tau_f + U * (1 - u) * r\r\n",
        "    dx = (1 - x) / tau_d - u * x * r\r\n",
        "    dh = (-h + J_EE * u * x * r - J_EI * r_inh + Iext + Ib) / tau\r\n",
        "    return du, dx, dh\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  @bp.odeint\r\n",
        "  def int_inh(h, t, r_exc):\r\n",
        "    h_I = (-h + J_IE * np.sum(r_exc) + Iinh) / tau_I\r\n",
        "    return h_I\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def log(h):\r\n",
        "    return alpha * np.log(1. + np.exp(h / alpha))\r\n",
        "\r\n",
        "  def update(self, _t):\r\n",
        "    self.u, self.x, self.h = self.int_exc(\r\n",
        "        self.u, self.x, self.h, _t, self.r, self.inh_r, self.input)\r\n",
        "    self.r = self.log(self.h)\r\n",
        "    self.inh_h = self.int_inh(self.inh_h, _t, self.r)\r\n",
        "    self.inh_r = self.log(self.inh_h)\r\n",
        "    self.input[:] = 0."
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# the external input\r\n",
        "\r\n",
        "I_inputs = np.zeros((int(duration / dt), cluster_num))\r\n",
        "for i in range(stimulus_num):\r\n",
        "    t_start = (Ts_interval + Ts_duration) * i + Ts_interval\r\n",
        "    t_end = t_start + Ts_duration\r\n",
        "    idx_start, idx_end = int(t_start / dt), int(t_end / dt)\r\n",
        "    I_inputs[idx_start: idx_end, i] = Iext_train\r\n",
        "\r\n",
        "\r\n",
        "# model.monwork running\r\n",
        "\r\n",
        "model = WorkingMemoryModel(cluster_num, monitors=['u', 'x', 'r', 'h'])\r\n",
        "model.run(duration, inputs=['input', I_inputs])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# visualization\r\n",
        "\r\n",
        "colors = list(dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS).keys())\r\n",
        "\r\n",
        "fig, gs = bp.visualize.get_figure(5, 1, 2, 12)\r\n",
        "fig.add_subplot(gs[0, 0])\r\n",
        "for i in range(stimulus_num):\r\n",
        "    plt.plot(model.mon.ts, model.mon.r[:, i], label='Cluster-{}'.format(i))\r\n",
        "plt.ylabel(\"$r (Hz)$\")\r\n",
        "plt.legend(loc='right')\r\n",
        "\r\n",
        "fig.add_subplot(gs[1, 0])\r\n",
        "hist_Jux = J_EE * model.mon.u * model.mon.x\r\n",
        "for i in range(stimulus_num):\r\n",
        "    plt.plot(model.mon.ts, hist_Jux[:, i])\r\n",
        "plt.ylabel(\"$J_{EE}ux$\")\r\n",
        "\r\n",
        "fig.add_subplot(gs[2, 0])\r\n",
        "for i in range(stimulus_num):\r\n",
        "    plt.plot(model.mon.ts, model.mon.u[:, i], colors[i])\r\n",
        "plt.ylabel('u')\r\n",
        "\r\n",
        "fig.add_subplot(gs[3, 0])\r\n",
        "for i in range(stimulus_num):\r\n",
        "    plt.plot(model.mon.ts, model.mon.x[:, i], colors[i])\r\n",
        "plt.ylabel('x')\r\n",
        "\r\n",
        "fig.add_subplot(gs[4, 0])\r\n",
        "for i in range(stimulus_num):\r\n",
        "    plt.plot(model.mon.ts, model.mon.r[:, i], colors[i])\r\n",
        "plt.ylabel('h')\r\n",
        "plt.xlabel('time [s]')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: try to encode one item in the model (Fig. 2)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: try to encode two items in the network (Fig. 3)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}